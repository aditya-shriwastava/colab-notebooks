{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "visual_odometry.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "HkPX4OQsnfk9",
        "U966xWx0Fmyv",
        "dyoKKQob65tQ",
        "SP9JeqJBtgkR",
        "ycUNnyo_nGwS",
        "yx397rOrnmKR",
        "Bz8rpVqyntlM",
        "IPQfvqjiF159",
        "PpTh60inLqW7"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aditya-shriwastava/colab-notebooks/blob/master/visual_odometry.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TODO\n",
        "- [ ] Compute trajectory in 3D (Up to scale)\n",
        "- [ ] Compare trajectory with ground truth data. (Whthout bundle adjustment)\n",
        "- [ ] Pose-Graph Optimization"
      ],
      "metadata": {
        "id": "iJh-acjz3zRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# pip3 install"
      ],
      "metadata": {
        "id": "HkPX4OQsnfk9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install scikit-image"
      ],
      "metadata": {
        "id": "zYVWFZawnnTj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# import"
      ],
      "metadata": {
        "id": "U966xWx0Fmyv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from skimage.measure import ransac\n",
        "\n",
        "from tqdm import tqdm, trange"
      ],
      "metadata": {
        "id": "p3vkC8-qgPts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load kitti dataset"
      ],
      "metadata": {
        "id": "dyoKKQob65tQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if \"2011_09_26_drive_0020_sync.zip\" not in os.listdir():\n",
        "  !wget https://s3.eu-central-1.amazonaws.com/avg-kitti/raw_data/2011_09_26_drive_0020/2011_09_26_drive_0020_sync.zip\n",
        "  !unzip  2011_09_26_drive_0020_sync.zip >/dev/null\n",
        "\n",
        "dataset_dir = \"./2011_09_26/2011_09_26_drive_0020_sync/image_02\"\n",
        "imgs_dir = os.path.join(dataset_dir, \"data\")\n",
        "timestamps_file_path = os.path.join(dataset_dir, \"timestamps.txt\")\n",
        "\n",
        "imgs_file_name = os.listdir(imgs_dir)\n",
        "imgs_file_name.sort()\n",
        "\n",
        "imgs_file_path = [os.path.join(imgs_dir, img_file_name) for img_file_name in imgs_file_name]\n",
        "kitti_imgs = np.array([cv2.imread(img_file_path) for img_file_path in imgs_file_path])"
      ],
      "metadata": {
        "id": "ANlQH-0d23I-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kitti_cam_calib = np.array([[7.215377e+02,0.000000e+00,6.095593e+02],\n",
        "                            [0.000000e+00,7.215377e+02,1.728540e+02],\n",
        "                            [0.000000e+00,0.000000e+00,1.000000e+00]])"
      ],
      "metadata": {
        "id": "j3xAvbXxi1p4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load deer_robot dataset"
      ],
      "metadata": {
        "id": "SP9JeqJBtgkR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if \"deer_robot.zip\" not in os.listdir():\n",
        "  !wget https://www.doc.ic.ac.uk/~wl208/lmdata/deer_robot.zip\n",
        "  !unzip  deer_robot.zip >/dev/null\n",
        "\n",
        "imgs_dir = \"./deer_robot/cam0/data\"\n",
        "metadata_file = \"./deer_robot/cam0/data.csv\"\n",
        "poses_gt_file = \"./deer_robot/poses.gt\"\n",
        "\n",
        "def load_metadata():\n",
        "  with open(metadata_file, 'r') as fd:\n",
        "      metadata = fd.readlines()\n",
        "\n",
        "  imgs_file = [\n",
        "      line.split(',')[1][:-1] for line in metadata[1:]\n",
        "  ]\n",
        "  imgs_path = [os.path.join(imgs_dir, f) for f in imgs_file]\n",
        "  timestamps = [float(line.split(',')[0])/1e9 for line in metadata[1:]]\n",
        "  return imgs_path, timestamps\n",
        "\n",
        "def load_poses_gt():\n",
        "  with open(poses_gt_file, 'r') as fd:\n",
        "    positions = []\n",
        "    orientations = []\n",
        "    for line in fd:\n",
        "      if line[0] == '#':\n",
        "        continue\n",
        "\n",
        "      split = line.split(',')\n",
        "      px = float(split[1])\n",
        "      py = float(split[2])\n",
        "      pz = float(split[3])\n",
        "      p = [px, py, pz]\n",
        "      positions.append(p)\n",
        "\n",
        "      qw = float(split[4])\n",
        "      qx = float(split[5])\n",
        "      qy = float(split[6])\n",
        "      qz = float(split[7])\n",
        "      q = [qx, qy, qz, qw]\n",
        "      orientations.append(q)\n",
        "  return np.array(positions), np.array(orientations)\n",
        "\n",
        "def load_batch(start, size):\n",
        "  imgs_path, timestamps = load_metadata()\n",
        "  imgs = np.array([\n",
        "      cv2.imread(img_path) for img_path in imgs_path[start:start+size]\n",
        "  ])\n",
        "  p, q = load_poses_gt()\n",
        "  return imgs, timestamps[start:start+size], p[start:start+size], q[start:start+size]\n",
        "\n",
        "deer_robot_imgs, deer_robot_timestamps, deer_robot_p, deer_robot_q = load_batch(0, 100)"
      ],
      "metadata": {
        "id": "AEtiskMotucN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "deer_robot_cam_calib = np.array([\n",
        "  [600, 0, 320],\n",
        "  [0, 600, 240],\n",
        "  [0,   0,   1]\n",
        "], dtype=np.float)"
      ],
      "metadata": {
        "id": "tDeGseMDuc8o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Disp utils"
      ],
      "metadata": {
        "id": "ycUNnyo_nGwS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def disp(img_tn1, kps_tn1, kps_t):\n",
        "  disp_img = img_tn1.copy()\n",
        "  for kp_tn1, kp_t in zip(kps_tn1, kps_t):\n",
        "    start_point = tuple(kp_tn1)\n",
        "    end_point = tuple(kp_t)\n",
        "    disp_img = cv2.circle(disp_img, start_point, 1, (0, 0, 255), 2)\n",
        "    disp_img = cv2.line(disp_img, start_point, end_point, (0, 255, 0), 1)\n",
        "  cv2_imshow(disp_img)\n",
        "\n",
        "def disp2(img_tn2, kps_tn2, kps_tn1, kps_t):\n",
        "  disp_img = img_tn2.copy()\n",
        "  for kp_tn2, kp_tn1, kp_t in zip(kps_tn2, kps_tn1, kps_t):\n",
        "    start_point = tuple(kp_tn2)\n",
        "    middle_point = tuple(kp_tn1)\n",
        "    end_point = tuple(kp_t)\n",
        "    disp_img = cv2.circle(disp_img, start_point, 1, (0, 0, 255), 2)\n",
        "    disp_img = cv2.line(disp_img, start_point, middle_point, (0, 255, 0), 1)\n",
        "    disp_img = cv2.line(disp_img, middle_point, end_point, (255, 0, 0), 1)\n",
        "  cv2_imshow(disp_img)"
      ],
      "metadata": {
        "id": "k8x8Xj3CnLcu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Essential matrix utils"
      ],
      "metadata": {
        "id": "yx397rOrnmKR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def triangulate(x_tn1, x_t, R, t):\n",
        "  \"\"\"\n",
        "  Args:\n",
        "    x_tn1: numpy array of shape (3,) representing normalized homogeneous\n",
        "      coordinate in img_tn1 of point to triangulate.\n",
        "    x_t: numpy array of shape (3,) representing normalized homogeneous\n",
        "      coordinate in img_t of point to triangulate.\n",
        "    R: numpy array of shape (3,3) representing rotation of camera frame\n",
        "      at time t wrt camera frame at time tn1.\n",
        "    t: numpy array of shape (3,) representing baseline vector between \n",
        "    camera frame at time t and camera frame at time tn1.\n",
        "  \"\"\"\n",
        "  A = np.array([\n",
        "    [np.dot(x_tn1, x_tn1), -np.dot(R @ x_t, x_tn1)],\n",
        "    [np.dot(x_tn1, R @ x_t), -np.dot(R @ x_t, R @ x_t)]\n",
        "  ])\n",
        "  b = np.array([np.dot(t, x_tn1) ,np.dot(t, R @ x_t)])\n",
        "  alpha, beta = np.linalg.inv(A) @ b\n",
        "  p_tn1 = alpha * x_tn1\n",
        "  p_t = t + (beta * (R @ x_t))\n",
        "  return (p_tn1 + p_t)/2\n",
        "\n",
        "def essential_to_Rt(E, x_tn1, x_t):\n",
        "  \"\"\"\n",
        "  Args:\n",
        "    E: numpy array of shape (3,3) representing Essential matrix.\n",
        "    x_tn1: numpy array of shape (3,) representing normalized homogeneous\n",
        "      coordinate in img_tn1.\n",
        "    x_tn1: numpy array of shape (3,) representing normalized homogeneous\n",
        "      coordinate in img_t corresponding to x_tn1.\n",
        "  \"\"\"\n",
        "  u,s,vt = np.linalg.svd(E)\n",
        "  w = np.array([[0,-1,0],\n",
        "                [1,0,0],\n",
        "                [0,0,1]])\n",
        "  R1 = u @ w.T @ vt\n",
        "  if np.linalg.det(R1) < 0:\n",
        "    R1 = -R1\n",
        "  R2 = u @ w @ vt\n",
        "  if np.linalg.det(R2) < 0:\n",
        "    R2 = -R2\n",
        "\n",
        "  t1 = u @ w @ np.diag(s) @ u.T\n",
        "  t1 = np.array([t1[2,1], t1[0,2], t1[1,0]])\n",
        "  t1 = t1/np.linalg.norm(t1)\n",
        "  t2 = -t1\n",
        "\n",
        "  # Resolve ambiguities by triangulation\n",
        "  p11_tn1 = triangulate(x_tn1, x_t, R1, t1)\n",
        "  p11_t = R1.T @ (p11_tn1 - t1)\n",
        "  if p11_tn1[2] > 0 and p11_t[2] > 0:\n",
        "    return R1, t1\n",
        "\n",
        "  p12_tn1 = triangulate(x_tn1, x_t, R1, t2)\n",
        "  p12_t = R1.T @ (p12_tn1 - t2)\n",
        "  if p12_tn1[2] > 0 and p12_t[2] > 0:\n",
        "    return R1, t2\n",
        "  \n",
        "  p21_tn1 = triangulate(x_tn1, x_t, R2, t1)\n",
        "  p21_t = R2.T @ (p21_tn1 - t1)\n",
        "  if p21_tn1[2] > 0 and p21_t[2] > 0:\n",
        "    return R2, t1\n",
        "\n",
        "  p22_tn1 = triangulate(x_tn1, x_t, R2, t2)\n",
        "  p22_t = R2.T @ (p22_tn1 - t2)\n",
        "  if p22_tn1[2] > 0 and p22_t[2] > 0:\n",
        "    return R2, t2\n",
        "  \n",
        "  raise Exception('Failed to resolve ambiguities!!')"
      ],
      "metadata": {
        "id": "cv0bA-7dVYlJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EssentialMatrixTransform():\n",
        "  def __init__(self):\n",
        "    # param contains essential matrix\n",
        "    self.params = np.eye(3)\n",
        "\n",
        "  def estimate(self, kps_tn1, kps_t):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "      kps_tn1: numpy array of shape (N,3) representing Keypoints in\n",
        "        normalized homogeneous coordinate from img_tn1\n",
        "      kps_t: numpy array of shape (N,3) representing Keypoints in\n",
        "        normalized homogeneous coordinate from img_t\n",
        "    \"\"\"\n",
        "    # Setup constraint matrix\n",
        "    A = np.column_stack((\n",
        "      kps_tn1[:,0] * kps_t[:,0],\n",
        "      kps_tn1[:,0] * kps_t[:,1],\n",
        "      kps_tn1[:,0] * kps_t[:,2],\n",
        "      kps_tn1[:,1] * kps_t[:,0],\n",
        "      kps_tn1[:,1] * kps_t[:,1],\n",
        "      kps_tn1[:,1] * kps_t[:,2],\n",
        "      kps_tn1[:,2] * kps_t[:,0],\n",
        "      kps_tn1[:,2] * kps_t[:,1],\n",
        "      kps_tn1[:,2] * kps_t[:,2]\n",
        "    ))\n",
        "\n",
        "    # Solve for nullsapce of the constraint matrix\n",
        "    u, s, vt = np.linalg.svd(A)\n",
        "    E = vt[-1,:].reshape(3,3)\n",
        "\n",
        "    # Enforcing Constraints:\n",
        "    # 1. First and Second singular values should be equal\n",
        "    # 2. Third singular value should be zero\n",
        "    u, s, vt = np.linalg.svd(E)\n",
        "    s[0] = s[1] = (s[0] + s[1])/2\n",
        "    s[2] = 0\n",
        "    self.params = u @ np.diag(s) @ vt\n",
        "\n",
        "    return True\n",
        "\n",
        "  def residuals(self, kps_tn1, kps_t):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "      kps_tn1: numpy array of shape (N,3) representing Keypoints in\n",
        "        normalized homogeneous coordinate from img_tn1\n",
        "      kps_t: numpy array of shape (N,3) representing Keypoints in\n",
        "        normalized homogeneous coordinate from img_t\n",
        "    \"\"\"\n",
        "    e_tn1 = kps_t @ self.params.T  # Epipilar line on tn1 image\n",
        "    e_t = kps_tn1 @ self.params  # Epipilar line on t image\n",
        "    \n",
        "    residue = (kps_tn1 * e_tn1).sum(axis = 1) # Residue from coplanarity constraint\n",
        "\n",
        "    return np.abs(residue) / np.sqrt(e_tn1[:,0]**2 + e_tn1[:,1]**2\n",
        "                                     + e_t[:,0]**2 + e_t[:,1]**2)"
      ],
      "metadata": {
        "id": "y6IwKqtdnqOR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test"
      ],
      "metadata": {
        "id": "Bz8rpVqyntlM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_tn1 = kitti_imgs[0]\n",
        "img_t = kitti_imgs[1]\n",
        "\n",
        "# Ground truth corresponding Keypoints in img_tn1 and img_t\n",
        "kps_tn1 = np.array([[838,233],[508,73],[514,180],[468,212],[587,141],[492,265],[986,212],[633, 42],[872,311],[544,124],\n",
        "                    [804,292],[858,247],[689,264],[161,256],[574,184],[637,80],[532,200],[514,202],[564,152],[586,169]])\n",
        "\n",
        "kps_t = np.array([[ 848,235],[506,72],[512,180],[462,212],[587,141],[486,268],[1037,217],[632,39],[886,317],[542,124],\n",
        "                  [814,298],[867,249],[690,267],[131,262],[572,184],[636,79],[528,200],[512,202],[564,152],[585,169]])\n",
        "kps_tn1_ = np.column_stack((kps_tn1, np.ones(len(kps_tn1)))) @ np.linalg.inv(kitti_cam_calib).T\n",
        "kps_t_ = np.column_stack((kps_t, np.ones(len(kps_t)))) @ np.linalg.inv(kitti_cam_calib).T\n",
        "\n",
        "disp(img_tn1, kps_tn1, kps_t)\n",
        "\n",
        "E = EssentialMatrixTransform()\n",
        "E.estimate(kps_tn1_, kps_t_)\n",
        "\n",
        "print(f\"Essential Matrix: {E.params}\")\n",
        "\n",
        "print(\"Residuals for corresponding points:\")\n",
        "print(E.residuals(kps_tn1_, kps_t_))\n",
        "\n",
        "print(\"Residuals for random points:\")\n",
        "permutation = np.random.choice(range(20), replace=False, size=20)\n",
        "print(E.residuals(kps_tn1_, kps_t_[permutation]))"
      ],
      "metadata": {
        "id": "3FLjLWi1nyBy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Features utils"
      ],
      "metadata": {
        "id": "IPQfvqjiF159"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features(img):\n",
        "  \"\"\"\n",
        "  Args\n",
        "    img: numpy array of shape (H,W,C) representing image\n",
        "  Returns\n",
        "    kps: numpy array of shape (N, 2) representing coordinates of N\n",
        "      keypoints detected\n",
        "    des: numpy array of shape (N, 32) representing 32 dim descriptor\n",
        "      of N keypoints\n",
        "  \"\"\"\n",
        "  img = np.expand_dims(np.mean(img, axis=2).astype(np.uint8), -1)\n",
        "  orb = cv2.ORB_create(nfeatures=5000)\n",
        "  kps, des = orb.detectAndCompute(img, None)\n",
        "  kps = np.array([[kp.pt[0], kp.pt[1]] for kp in kps]).astype(np.int32)\n",
        "  return kps, des\n",
        "\n",
        "\n",
        "def match_features(des_tn1, des_t):\n",
        "  bf_matcher = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
        "  matches = bf_matcher.match(des_tn1, des_t)\n",
        "  return np.array([[match.queryIdx, match.trainIdx] for match in matches])\n",
        "\n",
        "def match_features2(des_tn1, des_t):\n",
        "  bf_matcher = cv2.BFMatcher(cv2.NORM_HAMMING)\n",
        "  matches = bf_matcher.knnMatch(des_tn1, des_t, k=2)\n",
        "\n",
        "  idx_tn1, idx_t = [], []\n",
        "  for m1, m2 in matches:\n",
        "    # Lowe's ratio test\n",
        "    if m1.distance <= 1 * m2.distance:\n",
        "      if m1.distance < 32:\n",
        "        if m1.trainIdx not in idx_t:\n",
        "          idx_tn1.append(m1.queryIdx)\n",
        "          idx_t.append(m1.trainIdx)\n",
        "\n",
        "  assert len(idx_tn1) >= 8, f\"#matches: {len(idx_tn1)}\" \n",
        "  return np.array([idx_tn1, idx_t]).T"
      ],
      "metadata": {
        "id": "nzKaOBQyOYYS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Frame"
      ],
      "metadata": {
        "id": "PpTh60inLqW7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Frame:\n",
        "  def __init__(self, img, K):\n",
        "    self._img = img\n",
        "    self._K = K\n",
        "    self._kps, self._des = extract_features(img)\n",
        "    self._kps_ = self.normalize(self._kps)\n",
        "\n",
        "    self.frame2 = None\n",
        "    self.matches2 = None\n",
        "    self.E = None\n",
        "    self.R = None\n",
        "    self.t = None\n",
        "\n",
        "    self.matches3 = None\n",
        "    self.relative_scale = None\n",
        "\n",
        "  def triangulate(self, kps_idx):\n",
        "    assert self.frame2 is not None\n",
        "    matches2_idx, = np.where(self.matches2[:,0] == np.array(kps_idx))\n",
        "    assert len(matches2_idx) == 1\n",
        "    matches2_idx = matches2_idx[0]\n",
        "\n",
        "    return triangulate(\n",
        "      self.kps_[kps_idx],\n",
        "      self.frame2.kps_[self.matches2[matches2_idx,1]],\n",
        "      self.R,\n",
        "      self.t\n",
        "    )\n",
        "\n",
        "  def match2(self, frame2):\n",
        "    self.frame2 = frame2\n",
        "    self.matches2 = match_features2(self.des, self.frame2.des)\n",
        "\n",
        "    self.E, inliers = ransac(\n",
        "      (self.kps_[self.matches2[:,0]], self.frame2.kps_[self.matches2[:,1]]),\n",
        "      EssentialMatrixTransform,\n",
        "      min_samples=8,\n",
        "      residual_threshold=1e-3,\n",
        "      max_trials=100\n",
        "    )\n",
        "    self.matches2 = self.matches2[inliers]\n",
        "\n",
        "    self.R, self.t = essential_to_Rt(\n",
        "      self.E.params,\n",
        "      self.kps_[self.matches2[0,0]],\n",
        "      self.frame2.kps_[self.matches2[0,1]]\n",
        "    )\n",
        "  \n",
        "  def match3(self):\n",
        "    assert self.frame2 is not None\n",
        "    assert self.frame2.frame2 is not None\n",
        "    \n",
        "    self.matches3 = []\n",
        "    for i, kp in enumerate(self.matches2[:,1]):\n",
        "      j, = np.where(self.frame2.matches2[:,0] == np.array(kp))\n",
        "      assert len(j) in [0,1]\n",
        "      if len(j) == 1:\n",
        "        j = j[0]\n",
        "        assert self.matches2[i,1] == self.frame2.matches2[j,0]\n",
        "        self.matches3.append([self.matches2[i,0], self.matches2[i,1], self.frame2.matches2[j,1]])\n",
        "    self.matches3 = np.array(self.matches3)\n",
        "    self.update_relative_scale()\n",
        "\n",
        "  def update_relative_scale(self):\n",
        "    indices = np.random.choice(np.arange(len(self.matches3)), 10, replace=False).reshape(5,2)\n",
        "\n",
        "    relative_scale = []\n",
        "    for i, j in indices:\n",
        "      x_i_12 =self.triangulate(self.matches3[i,0])\n",
        "      x_j_12 =self.triangulate(self.matches3[j,0])\n",
        "      x_i_23 =self.frame2.triangulate(self.matches3[i,1])\n",
        "      x_j_23 =self.frame2.triangulate(self.matches3[j,1])\n",
        "\n",
        "      relative_scale.append(\n",
        "        np.linalg.norm(x_i_12 - x_j_12)/\n",
        "        np.linalg.norm(x_i_23 - x_j_23)\n",
        "      )\n",
        "    self.relative_scale = np.median(relative_scale)\n",
        "\n",
        "  def normalize(self, kps):\n",
        "    return np.column_stack((\n",
        "      kps,\n",
        "      np.ones(len(kps))\n",
        "    )) @ np.linalg.inv(self._K).T\n",
        "\n",
        "  @property\n",
        "  def img(self):\n",
        "    return self._img\n",
        "\n",
        "  @property\n",
        "  def kps(self):\n",
        "    return self._kps\n",
        "\n",
        "  @property\n",
        "  def kps_(self):\n",
        "    return self._kps_\n",
        "\n",
        "  @property\n",
        "  def des(self):\n",
        "    return self._des"
      ],
      "metadata": {
        "id": "RzU-eo03LuEg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main"
      ],
      "metadata": {
        "id": "SrJQPSjYoErG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# idxs = np.arange(100).reshape(50,2)[:,0]\n",
        "idxs = np.arange(len(kitti_imgs))\n",
        "\n",
        "frames = []\n",
        "for idx in tqdm(idxs):\n",
        "  frames.append(Frame(kitti_imgs[idx], kitti_cam_calib))\n",
        "  if len(frames) >= 2:\n",
        "    frames[-2].match2(frames[-1])\n",
        "    if len(frames) >= 3:\n",
        "      frames[-3].match3()"
      ],
      "metadata": {
        "id": "TguzHq4MjAhv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i = 0\n",
        "disp2(\n",
        "  frames[i].img,\n",
        "  frames[i].kps[frames[i].matches3[:,0]],\n",
        "  frames[i + 1].kps[frames[i].matches3[:,1]],\n",
        "  frames[i + 2].kps[frames[i].matches3[:,2]]\n",
        ")"
      ],
      "metadata": {
        "id": "g9U4DEGPNkky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(deer_robot_p.shape)\n",
        "plt.plot(deer_robot_p[:,1], deer_robot_p[:,0])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xPaKadrDgtMW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}